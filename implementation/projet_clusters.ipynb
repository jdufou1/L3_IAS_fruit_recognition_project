{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaged-england",
   "metadata": {},
   "source": [
    "## Partie : Prédiction basée sur les clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-creature",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exempt-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.utils import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-bubble",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stuffed-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_fichier = [\".jpg\"]\n",
    "\n",
    "def lire_images(cheminRacine, array, y, index):     \n",
    "    for lists in os.listdir(cheminRacine): \n",
    "        chemin = os.path.join(cheminRacine, lists) \n",
    "        filename, extension = os.path.splitext(chemin) \n",
    "        if extension in format_fichier:   \n",
    "            array.append(mpimg.imread(chemin))\n",
    "            y.append(index)\n",
    "        if os.path.isdir(chemin): \n",
    "            lire_images(chemin, array, y, index)\n",
    "images = []\n",
    "classes = []\n",
    "\n",
    "#remplissage de la liste d'images + classes\n",
    "lire_images(\"./Training/Banana\", images, classes, 0)\n",
    "lire_images(\"./Training/Corn\", images, classes, 1)\n",
    "lire_images(\"./Training/Strawberry\", images, classes, 2)\n",
    "lire_images(\"./Training/Raspberry\", images, classes, 3)\n",
    "lire_images(\"./Training/Clementine\", images, classes, 4)\n",
    "lire_images(\"./Training/Pear Williams\", images, classes, 5)\n",
    "lire_images(\"./Training/Nectarine\", images, classes, 6)\n",
    "lire_images(\"./Training/Orange\", images, classes, 7)\n",
    "lire_images(\"./Training/Lychee\", images, classes, 8)\n",
    "lire_images(\"./Training/Kiwi\", images, classes, 9)\n",
    "lire_images(\"./Training/Blueberry\", images, classes, 10)\n",
    "lire_images(\"./Training/Cherry 1\", images, classes, 11)\n",
    "lire_images(\"./Training/Apricot\", images, classes, 12)\n",
    "lire_images(\"./Training/Lemon\", images, classes, 13)\n",
    "lire_images(\"./Training/Watermelon\", images, classes, 14)\n",
    "lire_images(\"./Training/Tangelo\", images, classes, 15)\n",
    "lire_images(\"./Training/Plum\", images, classes, 16)\n",
    "lire_images(\"./Training/Peach\", images, classes, 17)\n",
    "lire_images(\"./Training/Kaki\", images, classes, 18)\n",
    "lire_images(\"./Training/Mango\", images, classes, 19)\n",
    "\n",
    "\n",
    "fruits = [\"Banane\",\"Mais\",\"Fraise\",\"Framboise\",\"Clementine\",\"Poire\",\n",
    "          \"Nectarine\",\"Orange\",\"Lychee\",\"Kiwi\",\"Mirtille\",\"Cerise\",\n",
    "          \"Abricot\",\"Citron\",\"Melon\",\"Tangelo\",\"Plum\",\"Peche\",\"Kaki\",\"Mangue\"]\n",
    "\n",
    "K = len(fruits)\n",
    "\n",
    "images,classes = shuffle(images, classes, random_state=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-ocean",
   "metadata": {},
   "source": [
    "## Fonctions de préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lyric-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_en_gris(img_orig):\n",
    "    im = np.zeros((img_orig.shape[0],img_orig.shape[1])) # On fait une copie de l'original\n",
    "    for i in range(img_orig.shape[0]):\n",
    "        for j in range(img_orig.shape[1]):\n",
    "            r, v, b = img_orig[i, j]\n",
    "            moyenne = np.mean(img_orig[i, j])\n",
    "            im[i, j] = int(moyenne)\n",
    "    return im\n",
    "\n",
    "def decouper_image(image, taille) :\n",
    "    return [image[x:x+taille,y:y+taille] for x in range(0,image.shape[0],taille) for y in range(0,image.shape[1],taille)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-surface",
   "metadata": {},
   "source": [
    "## Fonctions de preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numerous-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(images,nbPatch):\n",
    "    taillePatch = int((np.shape(images)[1]+np.shape(images)[2])/nbPatch)\n",
    "    X = np.zeros((np.shape(images)[0]*nbPatch,taillePatch,taillePatch))\n",
    "    insertion = 0\n",
    "    for i in range(np.shape(images)[0]):\n",
    "        image_grise = transformer_en_gris(images[i]) # Recuperation de l'image i\n",
    "        image_decoupe_list = decouper_image(image_grise,taillePatch) # image découpé\n",
    "        for j in range(nbPatch):\n",
    "            X[insertion] = image_decoupe_list[j]\n",
    "            insertion += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-modeling",
   "metadata": {},
   "source": [
    "## Algorithme des K-Moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welsh-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x1, x2) :\n",
    "    return np.abs(x1-x2).sum()\n",
    "\n",
    "class Kmoyennes:\n",
    "\n",
    "    def __init__(self,K, taillePatch, IterationMax): ## instanciation d'un objet du type de la classe.\n",
    "        self.K = K\n",
    "        self.taillePatch = taillePatch\n",
    "        self.N = 0\n",
    "        self.D = 0\n",
    "        self.IterationMax = IterationMax\n",
    "        self.affectations = np.zeros((self.N))\n",
    "        self.representants = np.zeros((self.K, self.taillePatch, self.taillePatch)) #les representants sont des patches\n",
    "    \n",
    "    def fit(self,X):\n",
    "        self.N = X.shape[0]\n",
    "        self.D = X.shape[1]\n",
    "        representants_initiaux = []\n",
    "        for i in range(self.K) :\n",
    "            representants_initiaux.append(np.random.randint(255, size=(self.taillePatch, self.taillePatch)))\n",
    "        representants = np.array(representants_initiaux)    \n",
    "        \n",
    "        for iterations in range(self.IterationMax):\n",
    "            affectations = self.maj_affectations(X, representants)\n",
    "            representants = self.maj_representants(X, affectations)\n",
    "            \n",
    "        self.representants = representants\n",
    "        self.affectations = affectations\n",
    "        return self.representants\n",
    "    \n",
    "    #retourne l'image moyenne (moyenne pixel a pixel de chaque patch du groupe X)\n",
    "    def barycentre(self, X) :\n",
    "        if X.shape[0] == 0 :\n",
    "            return None\n",
    "        return X.mean(axis=0)\n",
    "    \n",
    "    def maj_affectations(self, X, r):\n",
    "        N = X.shape[0]\n",
    "        K = r.shape[0]\n",
    "        a = np.zeros((N, K))\n",
    "        for n in range(N):\n",
    "            distances = np.zeros(K)\n",
    "            for k in range(K):\n",
    "                distances[k] = dist(X[n], r[k])\n",
    "            a[n, np.argmin(distances, axis=0)] = 1\n",
    "        return a\n",
    "\n",
    "    def maj_representants(self, X, a):\n",
    "        K = self.K\n",
    "        r = np.zeros((K,self.taillePatch, self.taillePatch))\n",
    "        for k in range(K):\n",
    "            masque = a[:,k] == 1\n",
    "            barycentre = self.barycentre(X[masque])\n",
    "            if barycentre is not None :\n",
    "                r[k] = barycentre\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "resistant-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retourne la matrice des appartenances des patches aux features pour chaque image\n",
    "def matrice_resultat_kmoyennes(affectationsKmeans, nbPatches):\n",
    "    resultats = np.zeros((int(affectationsKmeans.shape[0]/nbPatches),affectationsKmeans.shape[1]))\n",
    "    for image in range(resultats.shape[0]):\n",
    "        patchesImage = affectationsKmeans[(nbPatches*image):(nbPatches*image+nbPatches)]\n",
    "        somme = np.sum(patchesImage, axis=0)\n",
    "        somme[somme >= 1] = 1\n",
    "        resultats[image] = somme\n",
    "    return resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-resolution",
   "metadata": {},
   "source": [
    "## Modèle d'apprentissage : Le Bayésien Naïf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informed-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BayesienNaif_fit(X,y):\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    \n",
    "    pkd = np.zeros((K,D))\n",
    "    Pk = np.zeros((K,))\n",
    "    \n",
    "    for k in range(K):\n",
    "        mask = (y == k)\n",
    "        Pk[k] = np.sum(mask) / N\n",
    "        Xk = X[mask]\n",
    "        \n",
    "        for d in range(D):\n",
    "            count = 0\n",
    "            for n in range(Xk.shape[0]):\n",
    "                count += Xk[n , d]\n",
    "            \n",
    "            pkd[k , d] = count / Xk.shape[0]\n",
    "    \n",
    "    return pkd, Pk\n",
    "\n",
    "def BayesienNaif_predict(X, pkd, Pk):\n",
    "    epsilon = 1e-8\n",
    "    N = X.shape[0]\n",
    "    D = X.shape[1]\n",
    "    \n",
    "    y_pred = np.zeros(N)\n",
    "    \n",
    "    for n in range(N):\n",
    "        x = X[n]\n",
    "        score = np.zeros(K)\n",
    "        for k in range(K):\n",
    "            score[k] = (\n",
    "                np.log(Pk[k])\n",
    "                +\n",
    "                np.sum(\n",
    "                x * np.log(pkd[k] + epsilon)\n",
    "                    +\n",
    "                (1 - x) * np.log(1 - pkd[k] + epsilon)\n",
    "                )\n",
    "            )\n",
    "        k = np.argmax(score)\n",
    "        y_pred[n] = k\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-florist",
   "metadata": {},
   "source": [
    "## Fonctions de Cross-Validation sur le nombre de cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "placed-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appartenances_images_cibles(imagesValidation, nbPatches, representants) :\n",
    "    patchesImages = preprocessing(imagesValidation,nbPatches)\n",
    "    representantsCible = np.zeros((np.shape(imagesValidation)[0]*4,representants.shape[0]))\n",
    "    for n in range(patchesImages.shape[0]) :\n",
    "        distances = np.zeros(representants.shape[0])\n",
    "        for k in range(representants.shape[0]) :\n",
    "            distances[k] = dist(patchesImages[n], representants[k])\n",
    "        representantsCible[n][np.argmin(distances)] = 1\n",
    "    return matrice_resultat_kmoyennes(representantsCible, nbPatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "constant-award",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11051,)\n",
      "-----------------------------\n",
      "(8840,)\n",
      "(8840,)\n",
      "(2211,)\n",
      "(2211,)\n",
      "-----------------------------\n",
      "(7072,)\n",
      "(7072,)\n",
      "(1768,)\n",
      "(1768,)\n"
     ]
    }
   ],
   "source": [
    "#propTest entre 0 et 1\n",
    "def separer_train_test(images, classes, propTest) :\n",
    "    N = np.shape(images)[0]\n",
    "    Ntest = int(propTest * N)\n",
    "    return images[:Ntest], classes[:Ntest], images[Ntest :], classes[Ntest :]\n",
    "\n",
    "#indexVal entre 0 et 4\n",
    "def decouper_folds(imagesSansTest,classesSansTest, indexVal) :\n",
    "    indexReel = int((np.shape(imagesSansTest)[0]/5)*indexVal)\n",
    "    largeurIntervalle = int(np.shape(imagesSansTest)[0]/5)\n",
    "    \n",
    "    images_train =  imagesSansTest[: indexReel] + imagesSansTest[(indexReel+largeurIntervalle) : ]\n",
    "    classes_train = classesSansTest[: indexReel] + classesSansTest[(indexReel+largeurIntervalle) : ]\n",
    "    images_validation = imagesSansTest[indexReel:(indexReel+largeurIntervalle)]\n",
    "    classes_validation = classesSansTest[indexReel:(indexReel+largeurIntervalle)]\n",
    "        \n",
    "    return images_train, classes_train, images_validation, classes_validation\n",
    "\n",
    "images_sans_test, classes_sans_test, images_test, classes_test =  separer_train_test(images, classes, 0.80)\n",
    "images_train, classes_train, images_validation, classes_validation = decouper_folds(images_sans_test, classes_sans_test, 4)\n",
    "\n",
    "print(np.shape(images))\n",
    "print(\"-----------------------------\")\n",
    "print(np.shape(images_sans_test))\n",
    "print(np.shape(classes_sans_test))\n",
    "print(np.shape(images_test))\n",
    "print(np.shape(classes_test))     \n",
    "print(\"-----------------------------\")\n",
    "print(np.shape(images_train))\n",
    "print(np.shape(classes_train))\n",
    "print(np.shape(images_validation))\n",
    "print(np.shape(classes_validation))                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggressive-affiliation",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-36c9f849488e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mimages_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecouper_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_sans_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_sans_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mpatches_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbPatches\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pas optimal, en plus de prendre bcp de temps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mKm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKmoyennes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtaillePatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterationMax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mKm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4873f6919331>\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(images, nbPatch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnbPatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtaillePatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnbPatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnbPatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtaillePatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtaillePatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minsertion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#cross-validation\n",
    "\n",
    "nbPatches = 4\n",
    "nbClustersToTest = [60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125]\n",
    "erreurs = []\n",
    "\n",
    "images_sans_test, classes_sans_test, images_test, classes_test =  separer_train_test(images, classes, 0.70)\n",
    "\n",
    "for nb in nbClustersToTest :\n",
    "    accuracyCum = 0\n",
    "    for i in range(5) :\n",
    "        images_train, classes_train, images_validation, classes_validation = decouper_folds(images_sans_test, classes_sans_test, i)\n",
    "        patches_train = preprocessing(images_train, nbPatches) #pas optimal, en plus de prendre bcp de temps\n",
    "        Km = Kmoyennes(K=nb, taillePatch=25, IterationMax=10)\n",
    "        Km.fit(X=np.array(patches_train)) \n",
    "        representants = Km.representants\n",
    "        affectations = Km.affectations\n",
    "        X_train = matrice_resultat_kmoyennes(affectations, nbPatches)\n",
    "        pkd , Pk = BayesienNaif_fit(X_train, np.array(classes_train))\n",
    "        X_validation = appartenances_images_cibles(images_validation, nbPatches, representants)\n",
    "        ypred = BayesienNaif_predict(np.array(X_validation), pkd,Pk)\n",
    "        accuracy = np.sum(classes_validation == ypred) / np.shape(images_validation)[0]\n",
    "        print(f'accuracy : {accuracy} nb cluster : {nb} it : {i}')\n",
    "        accuracyCum += accuracy\n",
    "    accuracyCum /= 5\n",
    "    erreurs.append(1-accuracyCum)\n",
    "    print('fin itération')\n",
    "    \n",
    "    \n",
    "plt.plot(nbClustersToTest, erreurs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-ordinance",
   "metadata": {},
   "source": [
    "## Test et résultat du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test du modele\n",
    "\n",
    "images_sans_test, classes_sans_test, images_test, classes_test =  separer_train_test(images, classes, 0.70)\n",
    "\n",
    "nbPatches = 4\n",
    "patches_train = preprocessing(images_sans_test, nbPatches)\n",
    "Km = Kmoyennes(K=120, taillePatch=25, IterationMax=20)\n",
    "Km.fit(X=np.array(patches_train)) \n",
    "representants = Km.representants\n",
    "affectations = Km.affectations\n",
    "\n",
    "X_train = matrice_resultat_kmoyennes(affectations, nbPatches)\n",
    "pkd , Pk = BayesienNaif_fit(X_train, np.array(classes_sans_test))\n",
    "\n",
    "X_test = appartenances_images_cibles(images_test, nbPatches, representants)\n",
    "ypred = BayesienNaif_predict(np.array(X_test), pkd,Pk)\n",
    "accuracy = np.sum(classes_test == ypred) / np.shape(images_test)[0]\n",
    "\n",
    "value = 1000\n",
    "print(f'valeur de l\\'image : {classes_test[value]} valeur predite : {ypred[value]}')\n",
    "\n",
    "print(\"accuracy : \",np.sum(classes_test == ypred) / np.shape(images_test)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
